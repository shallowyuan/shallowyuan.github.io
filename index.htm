<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">		
		
		<meta charset="utf-8">
		
		<!-- ADD THE PAGE TITLE BELOW -->
		<title>Zehuan Yuan(袁泽寰)</title>
		
		<link rel="stylesheet" href="./zehuan/style.css">
	  
<script type="text/javascript">window.onerror=function(){return true;}</script></head>
	
	<body>	
		
		<div id="wrap">
		
			<div id="header">
				<div id="header-content">					
		
					<div id="AKA">
					<h1>Zehuan Yuan</h1>
					</div>
					<h2></h2> 
				    <p>
					I am currently a Tech Manager in <a href="https://www.bytedance.com/en/">Bytedance Inc.</a> Before that, I received both B.S. degree  and Ph.D. degree from  <a href="http://cs.nju.edu.cn/">Department of computer science and technology</a>,
					<a href="http://nju.edu.cn/"> Nanjing University</a>, under the supervision of Professor <a href="https://cs.nju.edu.cn/lutong/index.htm"> Tong Lu</a> . During my PhD study, I was lucky to visit the <a href="https://www.umich.edu"> University of Michigan</a> working with <a href="https://www.cs.princeton.edu/~jiadeng/"> Jia Deng</a> for one and a half year. 
					</p>
					<br>
					<p>
		            My interests lie in performing foundamental generative AI researach, building interesting and powerful AIGC capabilities, and applying these techs into real business scenarios. You can find and connect me from  <a href="https://scholar.google.com/citations?user=FqMOHnEAAAAJ&hl=zh-CN"> <font color="blue">Google Scholar</font></a> and <a href="https://www.linkedin.com/in/zehuan-yuan-40961182/"> <font color="blue">Linkedin</font></a>.
					</p>
					<br>
					<p><b>[<font color="red">Hiring!</font>]</b> Actively recruiting research scientists, algorithm engineers and research interns in China and Singapore. Feel free to contact me!</p>
					<p>
						<a href="https://job.toutiao.com/s/i2Svs7sG">[研究科学家]</a> <a href="https://job.toutiao.com/s/i2SvMX5X">[算法工程师]</a> <a href="https://job.toutiao.com/s/i2SoHFQV">[研究实习生]</a>
					</p>
					<div id="contact-details">	
						<p class="contact"><b>[<font color="red">Contact</font>]</b> <a href="mailto:%20yuanzehuan@bytedance.com">yuanzehuan@bytedance.com
						</a> </p>
					</div>	
									
				</div><!--end header-content-->
				
				<div id="header-photo">
						
					<!-- ADD A URL TO YOUR PHOTO HERE - 200x200px IN SIZE -->		
					<img src="./zehuan/my.jpeg">
					
				</div><!--end header-photo-->
			
			</div><!--end header-->
			
			<div class="line"></div>
			
			<div id="content">
			
				<div id="experience" class="cv-section">
				    <h4> News</h4>
				    <li style="list-style-type:square; margin-left:20px; margin-bottom:8px; display:list-item">
						We propose a new image generation  paradigm <a href="https://var.vision/"> VAR </a>|<a href="https://www.jiqizhixin.com/articles/2024-04-15-5?from=synced&keyword=VAR"> Report </a>|<a href="https://github.com/FoundationVision/VAR">code</a><font color="red"> [indicate scaling law in image generation]</font>
					</li>
					<li style="list-style-type:square; margin-left:20px; margin-bottom:8px; display:list-item">
						15 papers are accepted in 2023 (PAMI 3, CVPR 4, ICCV 3 , ICLR 2, NeurIPS 1, and 2 papers in SIGIR and ACM MM)
					</li>
				    <li style="list-style-type:square; margin-left:20px; margin-bottom:8px; display:list-item">
						Our <a href="https://github.com/ifzhang/ByteTrack">ByteTrack</a> ranks 1th of <a href="https://www.paperdigest.org/2023/01/most-influential-eccv-papers-2023-01/">the most influential papers in ECCV 2022</a>
					</li>
					<li style="list-style-type:square; margin-left:20px; margin-bottom:8px; display:list-item">
						15 papers are accepted in 2022 (TIP 2, CVPR 3, ECCV 5 , NeurIPS 3, and 2 papers in ICLR and AAAI)
					</li>
					<li style="list-style-type:square; margin-left:20px; margin-bottom:8px">
						Our global team wins the first prize in the Trusted Media Challenge (TMC) combatting deepfakes<a href="https://jobs.bytedance.com/en/blog/7092969057356728584?spread=XE4EC8K">[report]</a>
					</li>

				    <li style="list-style-type:square; margin-left:20px; margin-bottom:8px; display:list-item">
						Sparse R-CNN is accepted by CVPR 2021. We release the <a href="https://github.com/PeizeSun/SparseR-CNN">code</a><font color="red">[integrated by Detectron2, MMDetection, PaddlePaddle]</font>
					</li>
										<br>					
				</div>
						
			</div>
	
		</div>

</body></html>